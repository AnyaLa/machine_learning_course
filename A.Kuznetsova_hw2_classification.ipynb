{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификация текстов. Предсказание индекса Доу Джонса #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Постановка задачи и формулировка задания ##\n",
    "В качестве входных данных для предсказания индекса Доу Джонса по заголовкам новостей у нас есть датасет, в котором в качестве меток класса используется изменение индекса за день (1 -- повысился или не изменился, 0 -- понизился), в качестве данных для классификации -- топ 25 заголовков новостей за день. \n",
    "\n",
    "В наши задачи входит:\n",
    "1. Предварительная обработка текста;\n",
    "2. Обучение классификатора новостей для предсказания индекса;\n",
    "3. Поиск решений для улучшения результатов классификации.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритм решения поставленных задач ###\n",
    "Будет подробно описан в тексте ноутбука при написании кода."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание инструментов ##\n",
    "Ниже будут описаны используемые инструменты, принципы их работы, основная теория."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классификаторы ###\n",
    "\n",
    "Для решения задачи классификации мы решили воспользоваться двумя классификаторами и в качестве небольшого исследования оценить разницу в качестве классификации и выборе параметров для каждого из классификаторов.\n",
    "\n",
    "В экспериментах мы также последовательно будем применять векторизацию текстов при помощи модели мешка слов (CountVectorizer) и tf-idf преобразования. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Мультиномиальный наивный Байес**\n",
    "\n",
    "В методе классификации наивного Байеса определяется вероятность принадлежности документа к классу при том, что термин t определяет этот класс (апостериорная вероятность) и с учетом вероятности, с которой этот класс существует (апостериорная вероятность). \n",
    "\n",
    "Условная вероятность, а точнее ее логарифм, отражает вес термина (его важность) для этого документа. Таким образом, сложив веса терминов и сумму логарифмов вероятности какого-то класса мы получаем подтверждение его существования. \n",
    "\n",
    "Векторизация признаков в пространстве происходит при векторизации (модель мешка слов).\n",
    "\n",
    "Однако при представлении слова в виде вектора возникают некоторые проблемы: если слово предстает перед нами как вектор с координатами в пространстве, где координаты -- это признаки, то мы не считаем эти признаки разными, а приравниваем их друг к другу. То есть, если слово встречается в документе несколько раз, то в разных координатах мы присвоим ему одно и то же значение. Однако если в обучающей выборке пара термин-класс не встречается, то условная принадлежность термина к классу будет равна нулю, так как при перемножении вероятностей, где хотя бы одна равна нулю -- получаем ноль и значимость всех остальных признаков для отнесения к классу исчезает. \n",
    "\n",
    "Для того, чтобы избавиться от подобных случаев используется *сглаживание Лапласа*, в котором к частоте каждого термина прибавляется единица или любой другой коэффициент, не равный нулю. Выбор коэффициента зависит от суммы вероятностей предыдущих исходов (в идеальном случае сумма всех вероятностей должна равняться нулю), но если он не известен, то **alpha** просто выставляют 1. В нашем случае мы попробуем поэкспериментировать с разными значаениями и найти наилучший результат эмпирически."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Метод опорных векторов (Linear SVC)**\n",
    "\n",
    "Метод опорных векторов -- это метод основывающийся на поиске разделяющей плоскости в многомерном пространстве. Опорными векторами называются точки, расположенные ближе всего к разделяющей плоскости. \n",
    "\n",
    "Задача алгоритма -- максимизировать ширину разделяющей полосы, проходящей между экземплярами единиц двух классов. С максимизацией расстояния между единицами классов вероятность \"сомнения\" классификатора в принятии решения о принадлежности к классу снижается, в то время как если бы полоса была слишком узкой, вероятность отнести элементы к неверному классу сильно возрастает."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF преобразование ###\n",
    "\n",
    "TF-IDF мера помогает нормировать текст, определяя наиболее важные слова (с большим весом) и отсеивая слишком частотные или очень редкие слова. Эта мера также может помочь нам существенно улучшить качество классификации, для этого мы ее и будем использовать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сингулярное разложение ###\n",
    "\n",
    "Сингулярное разложение -- еще один способ улучшить качество классификации.\n",
    "\n",
    "Оно используется для того, чтобы сократить размерность пространства признаков, которыми мы характеризуем каждый документ.\n",
    "\n",
    "В результате разложения получается три матрицы, перемноженных между собой, на диагонали такой матрицы расположены сингулярные числа и их столько, сколько слов в нашем словаре. Мы оставляем заданное число этих сингулярных чисел (n компонент, которые задаются в методе), остальные обнуляем. В результате при обратном перемножении размерность пространства признаков (количество слов) сократится до заданного n. Это может улучшить качество классификации, поскольку мы избавляемся от ненужных признаков и оставляем только значимые."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import pointbiserialr\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_news_initial = pd.read_csv('/home/nst/mount/data/linguistics_hse/machine_learning/hw2_classification/stocknews/Combined_News_DJIA.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Label</th>\n",
       "      <th>Top1</th>\n",
       "      <th>Top2</th>\n",
       "      <th>Top3</th>\n",
       "      <th>Top4</th>\n",
       "      <th>Top5</th>\n",
       "      <th>Top6</th>\n",
       "      <th>Top7</th>\n",
       "      <th>Top8</th>\n",
       "      <th>...</th>\n",
       "      <th>Top16</th>\n",
       "      <th>Top17</th>\n",
       "      <th>Top18</th>\n",
       "      <th>Top19</th>\n",
       "      <th>Top20</th>\n",
       "      <th>Top21</th>\n",
       "      <th>Top22</th>\n",
       "      <th>Top23</th>\n",
       "      <th>Top24</th>\n",
       "      <th>Top25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>0</td>\n",
       "      <td>b\"Georgia 'downs two Russian warplanes' as cou...</td>\n",
       "      <td>b'BREAKING: Musharraf to be impeached.'</td>\n",
       "      <td>b'Russia Today: Columns of troops roll into So...</td>\n",
       "      <td>b'Russian tanks are moving towards the capital...</td>\n",
       "      <td>b\"Afghan children raped with 'impunity,' U.N. ...</td>\n",
       "      <td>b'150 Russian tanks have entered South Ossetia...</td>\n",
       "      <td>b\"Breaking: Georgia invades South Ossetia, Rus...</td>\n",
       "      <td>b\"The 'enemy combatent' trials are nothing but...</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Georgia Invades South Ossetia - if Russia ge...</td>\n",
       "      <td>b'Al-Qaeda Faces Islamist Backlash'</td>\n",
       "      <td>b'Condoleezza Rice: \"The US would not act to p...</td>\n",
       "      <td>b'This is a busy day:  The European Union has ...</td>\n",
       "      <td>b\"Georgia will withdraw 1,000 soldiers from Ir...</td>\n",
       "      <td>b'Why the Pentagon Thinks Attacking Iran is a ...</td>\n",
       "      <td>b'Caucasus in crisis: Georgia invades South Os...</td>\n",
       "      <td>b'Indian shoe manufactory  - And again in a se...</td>\n",
       "      <td>b'Visitors Suffering from Mental Illnesses Ban...</td>\n",
       "      <td>b\"No Help for Mexico's Kidnapping Surge\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-08-11</td>\n",
       "      <td>1</td>\n",
       "      <td>b'Why wont America and Nato help us? If they w...</td>\n",
       "      <td>b'Bush puts foot down on Georgian conflict'</td>\n",
       "      <td>b\"Jewish Georgian minister: Thanks to Israeli ...</td>\n",
       "      <td>b'Georgian army flees in disarray as Russians ...</td>\n",
       "      <td>b\"Olympic opening ceremony fireworks 'faked'\"</td>\n",
       "      <td>b'What were the Mossad with fraudulent New Zea...</td>\n",
       "      <td>b'Russia angered by Israeli military sale to G...</td>\n",
       "      <td>b'An American citizen living in S.Ossetia blam...</td>\n",
       "      <td>...</td>\n",
       "      <td>b'Israel and the US behind the Georgian aggres...</td>\n",
       "      <td>b'\"Do not believe TV, neither Russian nor Geor...</td>\n",
       "      <td>b'Riots are still going on in Montreal (Canada...</td>\n",
       "      <td>b'China to overtake US as largest manufacturer'</td>\n",
       "      <td>b'War in South Ossetia [PICS]'</td>\n",
       "      <td>b'Israeli Physicians Group Condemns State Tort...</td>\n",
       "      <td>b' Russia has just beaten the United States ov...</td>\n",
       "      <td>b'Perhaps *the* question about the Georgia - R...</td>\n",
       "      <td>b'Russia is so much better at war'</td>\n",
       "      <td>b\"So this is what it's come to: trading sex fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Label                                               Top1  \\\n",
       "0  2008-08-08      0  b\"Georgia 'downs two Russian warplanes' as cou...   \n",
       "1  2008-08-11      1  b'Why wont America and Nato help us? If they w...   \n",
       "\n",
       "                                          Top2  \\\n",
       "0      b'BREAKING: Musharraf to be impeached.'   \n",
       "1  b'Bush puts foot down on Georgian conflict'   \n",
       "\n",
       "                                                Top3  \\\n",
       "0  b'Russia Today: Columns of troops roll into So...   \n",
       "1  b\"Jewish Georgian minister: Thanks to Israeli ...   \n",
       "\n",
       "                                                Top4  \\\n",
       "0  b'Russian tanks are moving towards the capital...   \n",
       "1  b'Georgian army flees in disarray as Russians ...   \n",
       "\n",
       "                                                Top5  \\\n",
       "0  b\"Afghan children raped with 'impunity,' U.N. ...   \n",
       "1      b\"Olympic opening ceremony fireworks 'faked'\"   \n",
       "\n",
       "                                                Top6  \\\n",
       "0  b'150 Russian tanks have entered South Ossetia...   \n",
       "1  b'What were the Mossad with fraudulent New Zea...   \n",
       "\n",
       "                                                Top7  \\\n",
       "0  b\"Breaking: Georgia invades South Ossetia, Rus...   \n",
       "1  b'Russia angered by Israeli military sale to G...   \n",
       "\n",
       "                                                Top8  \\\n",
       "0  b\"The 'enemy combatent' trials are nothing but...   \n",
       "1  b'An American citizen living in S.Ossetia blam...   \n",
       "\n",
       "                         ...                          \\\n",
       "0                        ...                           \n",
       "1                        ...                           \n",
       "\n",
       "                                               Top16  \\\n",
       "0  b'Georgia Invades South Ossetia - if Russia ge...   \n",
       "1  b'Israel and the US behind the Georgian aggres...   \n",
       "\n",
       "                                               Top17  \\\n",
       "0                b'Al-Qaeda Faces Islamist Backlash'   \n",
       "1  b'\"Do not believe TV, neither Russian nor Geor...   \n",
       "\n",
       "                                               Top18  \\\n",
       "0  b'Condoleezza Rice: \"The US would not act to p...   \n",
       "1  b'Riots are still going on in Montreal (Canada...   \n",
       "\n",
       "                                               Top19  \\\n",
       "0  b'This is a busy day:  The European Union has ...   \n",
       "1    b'China to overtake US as largest manufacturer'   \n",
       "\n",
       "                                               Top20  \\\n",
       "0  b\"Georgia will withdraw 1,000 soldiers from Ir...   \n",
       "1                     b'War in South Ossetia [PICS]'   \n",
       "\n",
       "                                               Top21  \\\n",
       "0  b'Why the Pentagon Thinks Attacking Iran is a ...   \n",
       "1  b'Israeli Physicians Group Condemns State Tort...   \n",
       "\n",
       "                                               Top22  \\\n",
       "0  b'Caucasus in crisis: Georgia invades South Os...   \n",
       "1  b' Russia has just beaten the United States ov...   \n",
       "\n",
       "                                               Top23  \\\n",
       "0  b'Indian shoe manufactory  - And again in a se...   \n",
       "1  b'Perhaps *the* question about the Georgia - R...   \n",
       "\n",
       "                                               Top24  \\\n",
       "0  b'Visitors Suffering from Mental Illnesses Ban...   \n",
       "1                 b'Russia is so much better at war'   \n",
       "\n",
       "                                               Top25  \n",
       "0           b\"No Help for Mexico's Kidnapping Surge\"  \n",
       "1  b\"So this is what it's come to: trading sex fo...  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 852,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news_initial.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть I. Предобработка текста и работа с корреляциями ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка текста ###\n",
    "\n",
    "В нашем случае предобработка текстов будет заключаться в том, чтобы удалить знаки препинания и привести тексты к нижнему регистру, избавиться от символов кодировки binary, в которых была закодирована часть текстов.\n",
    "\n",
    "По нашему мнению, лемматизация или стемминг не сильно помогут в обработке, поскольку английский язык не такой флективный как, например, русский, где целых шесть лексем будут принадлежать к одной лемме, так как в русском языке 6 падежей (в английском языке для существительных будет всего две формы -- единственное и множественное число: *dog -- dogs*).\n",
    "\n",
    "Все остальные операции (векторизацию, удаление стоп-слов) можно выполнять из пакета **sklearn**.\n",
    "\n",
    "Функция `preprocess_to_list` принимает на вход датафрейм, а возвращает список текстов, где все 25 топовых заголовков за день будут представлены в виде одного текста. Это нужно для удобства работы с данными: все характеристики для корреляций мы будем считать именно по ним, а также извлекать признаки для обучения классификаторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(text_string):\n",
    "    cases = ('b\\'', 'b\\\"')\n",
    "    for prefix in cases:\n",
    "        if text_string.startswith(prefix):\n",
    "            text_string = text_string[1:]\n",
    "    low_text = text_string.lower()\n",
    "    del_punctuation = re.findall(r'\\w+', low_text)\n",
    "    str_heading_text = ' '.join(del_punctuation)\n",
    "    return str_heading_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_to_list(data_frame):\n",
    "    texts_list = []\n",
    "    for index in range(len(data_frame)):\n",
    "        single_row = data_frame.loc[index:index, :]\n",
    "        headings_array = single_row.get_values()\n",
    "        for row in headings_array:\n",
    "            row_texts_list = []\n",
    "            for heading in row:\n",
    "                if heading is np.nan:\n",
    "                    print('Heading type nan:', heading)\n",
    "                    row_texts_list.append('')                \n",
    "                    continue\n",
    "                str_heading_text = preprocess(heading)\n",
    "                row_texts_list.append(str_heading_text)\n",
    "            row_texts_list = ' '.join(row_texts_list)\n",
    "            texts_list.append(row_texts_list)\n",
    "    return texts_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "single_row = df_news_initial.loc[0:0, :]\n",
    "headings_array = single_row.get_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Есть ли корреляция между средней длинной текста за день и DJIA?**\n",
    "\n",
    "Поскольку одна из наших переменных (изменение индекса) дихотомическая, нам необходимо использовать метод точечной двухрядной корреляцию (Point-Biserial Correlation). Она является частным случаем корреляции Пирса\n",
    "\n",
    "Для получения индекса корреляции используем функцию из модуля `scipy.stats`, из которой на выходе получаем значение индекса корреляции (первое значение) и p-value (второе значение). Затем построим график распределения величин."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = df_news_initial['Label']\n",
    "labels = labels.get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_tops = df_news_initial.loc[:, 'Top1':'Top25']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1989"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_tops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Извлекаем параметры корреляции (подсчет средней длины текста за день). В функции необходимо учесть, что есть и пустые заголовки (nan). На выходе из функции `count_mean_per_row` получаем numpy array c посчитаным средним значением."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_mean_per_row(data_frame):\n",
    "    means_list = []\n",
    "    \n",
    "    for index in range(len(data_frame)):\n",
    "        single_row = data_frame.loc[index:index, :]\n",
    "        headings_array = single_row.get_values()\n",
    "        \n",
    "        for row in headings_array:\n",
    "            count_words_list = []\n",
    "            for heading in row:\n",
    "                if heading is np.nan:\n",
    "                    print('Heading type nan:', heading)\n",
    "                    count_words_list.append(0)\n",
    "                    continue\n",
    "                heading = preprocess(heading)\n",
    "                heading = heading.split()\n",
    "                count_words = (len(heading))\n",
    "                count_words_list.append(count_words)\n",
    "            row_mean = sum(count_words_list)/25\n",
    "            means_list.append(row_mean)\n",
    "\n",
    "            count_words_list.append(1)\n",
    "\n",
    "    means_array = np.array(means_list)\n",
    "    return means_array    \n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция проходится по каждому тексту из коллекции, удаляет знаки препинания и ненужные binary символы, считает длину отдельного заголовка, общую длину всех заголовков за день и находит среднее значение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heading type nan: nan\n",
      "Heading type nan: nan\n",
      "Heading type nan: nan\n",
      "Heading type nan: nan\n",
      "Heading type nan: nan\n",
      "Heading type nan: nan\n",
      "Heading type nan: nan\n"
     ]
    }
   ],
   "source": [
    "means = count_mean_per_row(df_tops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 15.28,  10.88,  14.48, ...,  15.6 ,  18.  ,  20.8 ])"
      ]
     },
     "execution_count": 914,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PointbiserialrResult(correlation=-0.0064443894451112821, pvalue=0.77393582182950416)"
      ]
     },
     "execution_count": 911,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_index = pointbiserialr(labels, means)\n",
    "corr_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAD8CAYAAACSCdTiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEz1JREFUeJzt3X2MHHd9x/H31+dLcCHFMT6qxA/YRCbgEkTCKUnllkIL\nxIkqO1AKdhs1BYRF2/RBpVETJUrTlIqC1Uc1BVIa8RQcwpOxkJFBNKhVRIzP5MFJjMnFhPjsiBiC\n05YY7Fy+/ePG7nq9ezt3t+t1fn6/pNPtzHxn5ntzv/l4d3bWF5mJJKlMs/rdgCSpdwx5SSqYIS9J\nBTPkJalghrwkFcyQl6SCGfKSVDBDXpIKZshLUsFm92vH8+fPzyVLlvRr95L0nLR9+/YfZuZQ3fq+\nhfySJUsYGRnp1+4l6TkpIr4/lXov10hSwQx5SSqYIS9JBTPkJalghrwkFcyQl6SCGfKSVLCOIR8R\nt0bEExHxQJvlERH/HBGjEXF/RFzQ/TYlSdNR58NQHwP+BfhEm+WXAsuqr4uAD1Xfu27jPXtZv2UX\n+w4c5Oy5c7j6knO5/PwFXL9xBxu27mE8k4EI1l60iPddft7R9a7fuIPb7n6Mdn/Ndu6cQW5c9YsA\nR7f/c6cN8PSh8ZbrzAp4tmHBshc/n937f8K4fy5XBWse940az7t252mr+UDL2kbttjeZ5nVe//Ih\n7vzO/iltoxem87PMVNT5Q94RsQT4cma+ssWyjwDfyMwN1fQu4HWZ+fhk2xweHs6pfOJ14z17ufYL\nOzh4ePzovDmDA1yw+IXc9ciTx9VfcfFi3nf5eVy/cQefuvuxjtufBQwMBIdNamnaVpwzj28/9tRx\n5+lvvmYBn9++95j5gwMBCYcb/uWYMzjA+99y3tHga3feN9Y0a7VOs07b6IXp/CytRMT2zByuW9+N\na/ILgD0N02PVvK5av2XXcb+0g4fHWwY8wIate4753smzYMBLM3TXI0+2PE83bN1z3PzD43lMwB+p\nXb9l19Hpdud9Y02zVus067SNXpjOz9IN3Qj5aDGvZVpGxLqIGImIkf37909pJ/sOHJxS/Xj1CmW8\nxisVSb01lfOw8Vxvd95Plgd1s2KqmTJT0/lZuqEbIT8GLGqYXgjsa1WYmbdk5nBmDg8N1f5P1AA4\ne+6cKdUPRBzzXVL/TOU8bDzX2533k+VB3ayYaqbM1HR+lm7oRshvAn63usvmYuCpTtfjp+PqS85l\nzuDAMfPmDA6w4px5LevXXrTomO+dzKK6Rihp2lacM6/lebr2okXHzR8cCAZnxXG1R96QhfbnfWNN\ns1brNOu0jV6Yzs/SDR3vromIDcDrgPkRMQb8JTAIkJkfBjYDlwGjwNPAO3rR6JE3JqZ6d82R795d\nI83MTO+uGX7JvCnfXTPZed9Oq3VOhrtrpvOzdEOtu2t6Yap310iS+nN3jSTpJGXIS1LBDHlJKpgh\nL0kFM+QlqWCGvCQVzJCXpIIZ8pJUMENekgpmyEtSwQx5SSqYIS9JBTPkJalghrwkFcyQl6SCGfKS\nVDBDXpIKZshLUsEMeUkqmCEvSQUz5CWpYIa8JBXMkJekghnyklQwQ16SCmbIS1LBDHlJKpghL0kF\nM+QlqWCGvCQVrFbIR8TKiNgVEaMRcU2L5Ysj4s6IuCci7o+Iy7rfqiRpqjqGfEQMADcDlwLLgbUR\nsbyp7Hrgjsw8H1gD/Gu3G5UkTV2dZ/IXAqOZuTszDwG3A6ubahL4+erxC4F93WtRkjRddUJ+AbCn\nYXqsmtfoRuCKiBgDNgN/1GpDEbEuIkYiYmT//v3TaFeSNBV1Qj5azMum6bXAxzJzIXAZ8MmIOG7b\nmXlLZg5n5vDQ0NDUu5UkTUmdkB8DFjVML+T4yzHvAu4AyMxvAs8D5nejQUnS9NUJ+W3AsohYGhGn\nMfHG6qammseAXweIiFcwEfJej5GkPusY8pn5DHAVsAXYycRdNA9GxE0Rsaoqey/w7oi4D9gA/F5m\nNl/SkSSdYLPrFGXmZibeUG2cd0PD44eAFd1tTZI0U37iVZIKZshLUsEMeUkqmCEvSQUz5CWpYIa8\nJBXMkJekghnyklQwQ16SCmbIS1LBDHlJKpghL0kFM+QlqWCGvCQVzJCXpIIZ8pJUMENekgpmyEtS\nwQx5SSqYIS9JBTPkJalghrwkFcyQl6SCGfKSVDBDXpIKZshLUsEMeUkqmCEvSQUz5CWpYLVCPiJW\nRsSuiBiNiGva1LwtIh6KiAcj4tPdbVOSNB2zOxVExABwM/BGYAzYFhGbMvOhhpplwLXAisz8cUS8\nuFcNS5Lqq/NM/kJgNDN3Z+Yh4HZgdVPNu4GbM/PHAJn5RHfblCRNR52QXwDsaZgeq+Y1ehnwsoi4\nKyLujoiV3WpQkjR9HS/XANFiXrbYzjLgdcBC4L8i4pWZeeCYDUWsA9YBLF68eMrNSpKmps4z+TFg\nUcP0QmBfi5ovZebhzPwesIuJ0D9GZt6SmcOZOTw0NDTdniVJNdUJ+W3AsohYGhGnAWuATU01G4HX\nA0TEfCYu3+zuZqOSpKnrGPKZ+QxwFbAF2AnckZkPRsRNEbGqKtsC/CgiHgLuBK7OzB/1qmlJUj2R\n2Xx5/cQYHh7OkZGRvuxbkp6rImJ7Zg7XrfcTr5JUMENekgpmyEtSwQx5SSqYIS9JBTPkJalghrwk\nFcyQl6SCGfKSVDBDXpIKZshLUsEMeUkqmCEvSQUz5CWpYIa8JBXMkJekghnyklQwQ16SCmbIS1LB\nDHlJKpghL0kFM+QlqWCGvCQVzJCXpIIZ8pJUMENekgpmyEtSwQx5SSqYIS9JBTPkJalgtUI+IlZG\nxK6IGI2Iayape2tEZEQMd69FSdJ0dQz5iBgAbgYuBZYDayNieYu6M4A/BrZ2u0lJ0vTUeSZ/ITCa\nmbsz8xBwO7C6Rd1fAx8EftrF/iRJM1An5BcAexqmx6p5R0XE+cCizPzyZBuKiHURMRIRI/v3759y\ns5KkqakT8tFiXh5dGDEL+AfgvZ02lJm3ZOZwZg4PDQ3V71KSNC11Qn4MWNQwvRDY1zB9BvBK4BsR\n8ShwMbDJN18lqf/qhPw2YFlELI2I04A1wKYjCzPzqcycn5lLMnMJcDewKjNHetKxJKm2jiGfmc8A\nVwFbgJ3AHZn5YETcFBGret2gJGn6ZtcpyszNwOameTe0qX3dzNuSJHWDn3iVpIIZ8pJUMENekgpm\nyEtSwQx5SSqYIS9JBTPkJalghrwkFcyQl6SCGfKSVDBDXpIKZshLUsEMeUkqmCEvSQUz5CWpYIa8\nJBXMkJekghnyklQwQ16SCmbIS1LBDHlJKpghL0kFM+QlqWCGvCQVzJCXpIIZ8pJUMENekgpmyEtS\nwQx5SSpYrZCPiJURsSsiRiPimhbL/ywiHoqI+yPi6xHxku63Kkmaqo4hHxEDwM3ApcByYG1ELG8q\nuwcYzsxXAZ8DPtjtRiVJU1fnmfyFwGhm7s7MQ8DtwOrGgsy8MzOfribvBhZ2t01J0nTUCfkFwJ6G\n6bFqXjvvAr4yk6YkSd0xu0ZNtJiXLQsjrgCGgV9ts3wdsA5g8eLFNVuUJE1XnWfyY8CihumFwL7m\nooh4A3AdsCozf9ZqQ5l5S2YOZ+bw0NDQdPqVJE1BnZDfBiyLiKURcRqwBtjUWBAR5wMfYSLgn+h+\nm5Kk6egY8pn5DHAVsAXYCdyRmQ9GxE0RsaoqWw+8APhsRNwbEZvabE6SdALVuSZPZm4GNjfNu6Hh\n8Ru63JckqQv8xKskFcyQl6SCGfKSVDBDXpIKZshLUsEMeUkqmCEvSQUz5CWpYIa8JBXMkJekghny\nklQwQ16SCmbIS1LBDHlJKpghL0kFM+QlqWCGvCQVzJCXpIIZ8pJUMENekgpmyEtSwQx5SSqYIS9J\nBTPkJalghrwkFcyQl6SCGfKSVDBDXpIKZshLUsEMeUkq2Ow6RRGxEvgnYAD4aGb+bdPy04FPAK8B\nfgS8PTMf7W6rU7fxnr2s37KLvQcOMhDBeCYL5s7h6kvO5fLzFwBw/cYdfHrrYzybx647EMHaixbx\nvsvPO2b+9Rt38Km7HztRP4I0YwEkEAHZMM4HZ8HhZydfd8HcObz+5UN8+b7HOXDw8NH5cwZnMSuC\nnxwaB2AgYLxh2yvOmcdt7/6llts8cl7uO3CQs6vzEThu3pFztM763agtVWTm5AURA8B3gTcCY8A2\nYG1mPtRQ8wfAqzLzPRGxBnhzZr59su0ODw/nyMjITPtva+M9e7n2Czs4eHj8uGVzBgd4/1vOY+T7\nT3YM7CsuXnw06A14qb5WQd/qvBwcCEg43PBM68g52hzIrdbvRu1zSURsz8zhuvV1LtdcCIxm5u7M\nPATcDqxuqlkNfLx6/Dng1yMi6jbRC+u37GoZ8AAHD4+zfssuNmzd03E7jTV16iVNuOuRJ4+b1+q8\nPDyexwQ8/P85Wmf9btSWrE7ILwAa022smteyJjOfAZ4CXtS8oYhYFxEjETGyf//+6XVc074DBzsu\nH+/wKgY4pqZOvaT2Op2XnWrbrT/T2pLVCflWz8ib065ODZl5S2YOZ+bw0NBQnf6m7ey5czouH6jx\nYqOxpk69pPY6nZedatutP9PaktUJ+TFgUcP0QmBfu5qImA28EDj+tdoJdPUl5zJncKDlsjmDA1x9\nybmsvWhRy+WNGmvq1EuasOKcecfNa3VeDg4Eg7OOfQJ15Byts343aktW5+6abcCyiFgK7AXWAL/d\nVLMJuBL4JvBW4D+y0zu6PXbkjZXJ7q45UlP37pojj33zVc8lJ9PdNY3n5XTurmm3/kxrS9bx7hqA\niLgM+EcmbqG8NTP/JiJuAkYyc1NEPA/4JHA+E8/g12Tm7sm22eu7aySpRFO9u6bWffKZuRnY3DTv\nhobHPwV+q+5OJUknhp94laSCGfKSVDBDXpIKZshLUsEMeUkqmCEvSQUz5CWpYLU+DNWTHUfsB77f\nl53DfOCHfdp3O/ZU38nYlz3VdzL29Vzq6SWZWfs//+pbyPdTRIxM5RNjJ4I91Xcy9mVP9Z2MfZXc\nk5drJKlghrwkFexUDflb+t1AC/ZU38nYlz3VdzL2VWxPp+Q1eUk6VZyqz+Ql6ZRQVMhHxK0R8URE\nPNAwb15EfC0iHq6+n9lm3Surmocj4soe97Q+Ir4TEfdHxBcjYm6bdR+NiB0RcW9EdO0/32/T040R\nsbfa173V3xBote7KiNgVEaMRcU23epqkr8809PRoRNzbZt1eHatFEXFnROyMiAcj4k+q+X0bV5P0\n1LdxNUlPfRtXk/TU7zH1vIj4VkTcV/X1V9X8pRGxtRorn4mI09qsf211nHZFxCUdd5iZxXwBrwUu\nAB5omPdB4Jrq8TXAB1qsNw/YXX0/s3p8Zg97ehMwu3r8gVY9VcseBeafoON0I/DnHdYbAB4BXgqc\nBtwHLO9lX03L/w644QQfq7OAC6rHZwDfBZb3c1xN0lPfxtUkPfVtXLXr6SQYUwG8oHo8CGwFLgbu\nYOIPLgF8GPj9Fusur47P6cDS6rgNTLa/op7JZ+Z/cvzfll0NfLx6/HHg8harXgJ8LTOfzMwfA18D\nVvaqp8z8amY+U03ezcTfzT1h2hynOi4ERjNzd2YeAm5n4vj2vK+ICOBtwIZu7a9mT49n5rerx/8D\n7AQW0Mdx1a6nfo6rSY5THT0ZV5166uOYysz832pysPpK4NeAz1Xz242p1cDtmfmzzPweMMrE8Wur\nqJBv4xcy83GY+KUDL25RswDY0zA9Rv0BOlPvBL7SZlkCX42I7RGx7gT0clX1Uv/WNpcf+nmcfgX4\nQWY+3GZ5z49VRCxh4k9cbuUkGVdNPTXq27hq0VPfx1Wb49S3MRURA9VloieY+Mf/EeBAwz/S7Y7B\nlI/VqRDydUSLeT2/7SgirgOeAW5rU7IiMy8ALgX+MCJe28N2PgScA7waeJyJl7HN+nKcKmuZ/BlX\nT49VRLwA+Dzwp5n533VXazGva8erXU/9HFcteur7uJrkd9e3MZWZ45n5aiZebV0IvKJVWYt5Uz5W\np0LI/yAizgKovj/RomYMWNQwvRDY18umqjfhfgP4nawutjXLzH3V9yeAL9LhZdlMZOYPqoH3LPBv\nbfZ1wo8TQETMBt4CfKZdTS+PVUQMMhESt2XmF6rZfR1XbXrq67hq1VO/x9Ukx6mvY6phHweAbzBx\nTX5u1Re0PwZTPlanQshvAo7c1XAl8KUWNVuAN0XEmdXLyTdV83oiIlYCfwGsysyn29Q8PyLOOPK4\n6umBVrVd6umshsk3t9nXNmBZdRfAacAaJo5vr70B+E5mjrVa2MtjVV23/XdgZ2b+fcOivo2rdj31\nc1xN0lPfxtUkvzvo75gaiurOp4iYU/WyE7gTeGtV1m5MbQLWRMTpEbEUWAZ8a9Iddvud435+MfHS\n63HgMBP/4r0LeBHwdeDh6vu8qnYY+GjDuu9k4k2MUeAdPe5plInravdWXx+uas8GNlePX8rEu+j3\nAQ8C1/W4p08CO4D7q4F0VnNP1fRlTNyl8Eg3e2rXVzX/Y8B7mmpP1LH6ZSZeDt/f8Pu6rJ/japKe\n+jauJumpb+OqXU8nwZh6FXBP1dcDVHf3VPv8VvV7/CxwejV/FXBTw/rXVcdpF3Bpp/35iVdJKtip\ncLlGkk5ZhrwkFcyQl6SCGfKSVDBDXpIKZshLUsEMeUkqmCEvSQX7P4ePsFswk/0UAAAAAElFTkSu\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9865dc3160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(means, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку индекс корреляции близок к нулю, можно считать, что корреляции между двумя признаками нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Есть ли корреляция между количеством упоминаний Барака Обамы и США в день и DJIA?**\n",
    "\n",
    "Посчитаем количество упоминаний Барака Обамы и США в день. Учтем все возможные написания США (USA, U.S., US, United States, America). Обратим внимание, что для того, чтобы найти все упоминания в тексте, нам не надо приводить его к нижнему регистру иначе сочетания символов могут войти в часть другого слова. Например: **usa**ge.\n",
    "\n",
    "Ищем следующие строки:\n",
    "- Obama\n",
    "- Barack Obama\n",
    "- USA\n",
    "- U.S.\n",
    "- US\n",
    "- United States\n",
    "- America\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_higher_case(data_frame):\n",
    "    texts_list = []\n",
    "    for index in range(len(data_frame)):\n",
    "        single_row = data_frame.loc[index:index, :]\n",
    "        headings_array = single_row.get_values()\n",
    "        for row in headings_array:\n",
    "            row_texts_list = []\n",
    "            for heading in row:\n",
    "                if heading is np.nan:\n",
    "                    print('Heading type nan:', heading)\n",
    "                    row_texts_list.append('')                \n",
    "                    continue\n",
    "                del_punctuation = re.findall(r'\\w+', heading)\n",
    "                str_heading_text = ' '.join(del_punctuation)\n",
    "                row_texts_list.append(str_heading_text)\n",
    "            row_texts_list = ' '.join(row_texts_list)\n",
    "            texts_list.append(row_texts_list)\n",
    "    return texts_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heading type nan: nan\n",
      "Heading type nan: nan\n",
      "Heading type nan: nan\n",
      "Heading type nan: nan\n",
      "Heading type nan: nan\n",
      "Heading type nan: nan\n",
      "Heading type nan: nan\n"
     ]
    }
   ],
   "source": [
    "us_obama_lst = preprocess_higher_case(df_tops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пишем функцию, которая считает количество соответствий в тексте всем обозначенным случаям. Берем на вход строку текста, объединяем по вертикальной черте, что в регулярных выражениях интерпретируется как \"или\". Ищем в строке все случаи, соответствующие нашему регулярному выражению и чтобы сохранить значение итератора упаковываем его в тьюпл, берем его длину."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1061,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_obama_us_line(text_line):\n",
    "    cases = ('Obama', 'Barack Obama', 'USA', 'U.S.', 'US', 'United States', 'America')\n",
    "    \n",
    "    regexp = '|'.join(cases)\n",
    "    return len(tuple(re.finditer(regexp, text_line)))\n",
    "    \n",
    "    \n",
    "#     while True:\n",
    "        \n",
    "#         case_indices = [text_line.find(case, index) for case in cases]\n",
    "#         if all([case_index == -1 for case_index in case_indices]):\n",
    "#             return case_count\n",
    "\n",
    "#         case_count += 1\n",
    "#         positive_indices = [case_index for case_index in case_indices if case_index != -1]\n",
    "#         min_index = min(positive_indices)\n",
    "#         index = min_index + 1\n",
    "\n",
    "assert count_obama_us_line('Obama in USA') == 2\n",
    "assert count_obama_us_line('God and religion') == 0\n",
    "assert count_obama_us_line('USACK Obama') == 2, count_obama_us_line('USACK Obama')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующая функция берет уже не одну строку, а список текстов. Так мы можем обсчитать каждый из них в цикле."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_obama_us(text_list):\n",
    "    count = []\n",
    "    for text in text_list:\n",
    "        num_words = count_obama_us_line(text)\n",
    "        count.append(num_words)\n",
    "    count_array = np.array(count)\n",
    "    return count_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_obama_us = count_obama_us(us_obama_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1056,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PointbiserialrResult(correlation=0.00067622893237813766, pvalue=0.9759556853451169)"
      ]
     },
     "execution_count": 1056,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_index = pointbiserialr(labels, c_obama_us)\n",
    "corr_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1057,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEeZJREFUeJzt3X2wXHV9x/H314QoVcqDuVjMg0EamabSFroToLSWDiIB\nOwl1rE0GRloZMoylraNlGgeGcaiOD0y12lLbYBlFKQ9axYzGiYzi2GFIyo08g5FLiuYSSiJPWsWG\n0G//2JPMstl79+y9e3dvfrxfM3fuOb/z/e1+Offsh3PPns2NzESSVJaXDbsBSVL/Ge6SVCDDXZIK\nZLhLUoEMd0kqkOEuSQUy3CWpQIa7JBXIcJekAs0d1hPPnz8/lyxZMqynl6SD0tatW3+cmSPd6oYW\n7kuWLGF0dHRYTy9JB6WI+GGdOi/LSFKBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUoK7hHhHX\nRsSuiLh/gu0REZ+KiLGIuDciTup/m5KkXtT5ENNngX8Erptg+9nA0urrZODT1fe+W7Lu6weMPfqR\ntzrf+QOZf/KHbuWJn+7Zv/6aw+ax5bIza88/75o7uP2Rp/avn3bcUVx/0am155/58e/w8K6f7V9f\nevQrufW9p9eeP12X33IfN2zZwQuZzIlgzcmL+OC5Jwzs+QFuuesxrtq0jZ3PPMdrjziUS886nnNP\nXDDQHqZjkP13PXPPzO8CT01Ssgq4Lps2A0dExDH9anCfTi/Mycad7/x+zm8PdoAnfrqHkz90a635\n7cEOcPsjT3HeNXfUmt8e7AAP7/oZZ378O7XmT9flt9zHFzb/iBcyAXghky9s/hGX33LfQJ4fmsH4\n/i/fx2PPPEcCjz3zHO//8n3cctdjA+thOgbdfz+uuS8AdrSsj1djUjHag73beLv2YO823q492LuN\n99sNW3b0ND4Trtq0jeeef+FFY889/wJXbdo2sB6mY9D99yPco8NYdiyMWBsRoxExunv37j48taRB\n2HfGXnd8Jux85rmexmebQfffj3AfBxa1rC8EdnYqzMz1mdnIzMbISNd/1EzSLDEnOp3DTTw+E157\nxKE9jc82g+6/H+G+AXhnddfMKcCzmfl4Hx5XmjVec9i8nsbbnXbcUT2Nt1t69Ct7Gu+3NScv6ml8\nJlx61vEcesicF40desgcLj3r+IH1MB2D7r/OrZA3AHcAx0fEeERcGBEXR8TFVclGYDswBlwDvHsm\nGp3oroa6dzs43/nTmb/lsjMPCPJe7pa5/qJTDwjyXu6WufW9px8Q5IO8W+aD557A+acs3n+mPieC\n809ZPNC7Zc49cQEfftsJLDjiUAJYcMShfPhtJxw0d8sMuv/IAV4za9VoNNJ/z12SehMRWzOz0a3O\nT6hKUoEMd0kqkOEuSQUy3CWpQIa7JBXIcJekAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCG\nuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5JBTLcJalAhrskFchwl6QCGe6SVCDDXZIKZLhL\nUoEMd0kqkOEuSQUy3CWpQIa7JBXIcJekAtUK94hYERHbImIsItZ12L44Im6LiLsi4t6IOKf/rUqS\n6uoa7hExB7gaOBtYBqyJiGVtZZcDN2fmicBq4J/63agkqb46Z+7LgbHM3J6Ze4AbgVVtNQn8crV8\nOLCzfy1KknpVJ9wXADta1sersVYfAM6PiHFgI/AXnR4oItZGxGhEjO7evXsK7UqS6qgT7tFhLNvW\n1wCfzcyFwDnA5yPigMfOzPWZ2cjMxsjISO/dSpJqqRPu48CilvWFHHjZ5ULgZoDMvAN4BTC/Hw1K\nknpXJ9zvBJZGxLERMY/mG6Yb2mp+BJwBEBG/RjPcve4iSUPSNdwzcy9wCbAJeIjmXTEPRMSVEbGy\nKnsfcFFE3APcAPxpZrZfupEkDcjcOkWZuZHmG6WtY1e0LD8InNbf1iRJU+UnVCWpQIa7JBXIcJek\nAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ\n4S5JBTLcJalAhrskFchwl6QCGe6SVCDDXZIKZLhLUoEMd0kqkOEuSQUy3CWpQIa7JBXIcJekAhnu\nklQgw12SClQr3CNiRURsi4ixiFg3Qc07IuLBiHggIv6tv21Kknoxt1tBRMwBrgbOBMaBOyNiQ2Y+\n2FKzFHg/cFpmPh0RR89Uw5Kk7uqcuS8HxjJze2buAW4EVrXVXARcnZlPA2Tmrv62KUnqRZ1wXwDs\naFkfr8ZavQF4Q0TcHhGbI2JFvxqUJPWu62UZIDqMZYfHWQqcDiwE/iMi3piZz7zogSLWAmsBFi9e\n3HOzkqR66py5jwOLWtYXAjs71Hw1M5/PzP8CttEM+xfJzPWZ2cjMxsjIyFR7liR1USfc7wSWRsSx\nETEPWA1saKu5BfgDgIiYT/MyzfZ+NipJqq9ruGfmXuASYBPwEHBzZj4QEVdGxMqqbBPwZEQ8CNwG\nXJqZT85U05KkyUVm++XzwWg0Gjk6OjqU55akg1VEbM3MRrc6P6EqSQUy3CWpQIa7JBXIcJekAhnu\nklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5J\nBTLcJalAhrskFchwl6QCGe6SVCDDXZIKZLhLUoEMd0kqkOEuSQUy3CWpQIa7JBXIcJekAhnuklQg\nw12SClQr3CNiRURsi4ixiFg3Sd3bIyIjotG/FiVJveoa7hExB7gaOBtYBqyJiGUd6g4D/hLY0u8m\nJUm9qXPmvhwYy8ztmbkHuBFY1aHub4GPAb/oY3+SpCmoE+4LgB0t6+PV2H4RcSKwKDO/NtkDRcTa\niBiNiNHdu3f33KwkqZ464R4dxnL/xoiXAZ8A3tftgTJzfWY2MrMxMjJSv0tJUk/qhPs4sKhlfSGw\ns2X9MOCNwHci4lHgFGCDb6pK0vDUCfc7gaURcWxEzANWAxv2bczMZzNzfmYuycwlwGZgZWaOzkjH\nkqSuuoZ7Zu4FLgE2AQ8BN2fmAxFxZUSsnOkGJUm9m1unKDM3Ahvbxq6YoPb06bclSZoOP6EqSQUy\n3CWpQIa7JBXIcJekAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQVyHCXpAIZ7pJUIMNd\nkgpkuEtSgQx3SSqQ4S5JBTLcJalAhrskFchwl6QCGe6SVCDDXZIKZLhLUoEMd0kqkOEuSQUy3CWp\nQIa7JBXIcJekAhnuklSgWuEeESsiYltEjEXEug7b3xsRD0bEvRHxrYh4Xf9blSTV1TXcI2IOcDVw\nNrAMWBMRy9rK7gIamfkbwJeAj/W7UUlSfXXO3JcDY5m5PTP3ADcCq1oLMvO2zPx5tboZWNjfNiVJ\nvagT7guAHS3r49XYRC4EvjGdpiRJ0zO3Rk10GMuOhRHnAw3g9yfYvhZYC7B48eKaLUqSelXnzH0c\nWNSyvhDY2V4UEW8GLgNWZub/dnqgzFyfmY3MbIyMjEylX0lSDXXC/U5gaUQcGxHzgNXAhtaCiDgR\n+Beawb6r/21KknrRNdwzcy9wCbAJeAi4OTMfiIgrI2JlVXYV8CrgixFxd0RsmODhJEkDUOeaO5m5\nEdjYNnZFy/Kb+9yXJGka/ISqJBXIcJekAhnuklQgw12SCmS4S1KBDHdJKpDhLkkFMtwlqUCGuyQV\nyHCXpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5JBTLcJalAhrskFchwl6QCGe6SVCDDXZIKZLhLUoEM\nd0kqkOEuSQUy3CWpQIa7JBXIcJekAhnuklQgw12SCmS4S1KBDHdJKtDcOkURsQL4JDAH+ExmfqRt\n+8uB64DfBp4E/iQzH+1vq7Bk3dcPGHv0I291vvMPivnnXXMHtz/y1P710447iusvOnVg8/XS0vXM\nPSLmAFcDZwPLgDURsayt7ELg6cz8VeATwEf73WinF9Zk4853/mya3x7MALc/8hTnXXPHQObrpafO\nZZnlwFhmbs/MPcCNwKq2mlXA56rlLwFnRET0r03p4NYezN3G+z1fLz11wn0BsKNlfbwa61iTmXuB\nZ4FXtz9QRKyNiNGIGN29e/fUOpYkdVUn3DudgecUasjM9ZnZyMzGyMhInf4kSVNQJ9zHgUUt6wuB\nnRPVRMRc4HDA3xelymnHHdXTeL/n66WnTrjfCSyNiGMjYh6wGtjQVrMBuKBafjvw7cw84Mx9Oia6\nK6Hu3QrOd/4w519/0akHBHEvd7tMd75eeqJOBkfEOcDf07wV8trM/FBEXAmMZuaGiHgF8HngRJpn\n7Kszc/tkj9loNHJ0dHTa/wGS9FISEVszs9GtrtZ97pm5EdjYNnZFy/IvgD/utUlJ0szwE6qSVCDD\nXZIKZLhLUoEMd0kqkOEuSQUy3CWpQIa7JBWo1oeYZuSJI3YDP5zi9PnAj/vYTr/Z3/TY3/TY3/TN\n5h5fl5ld/3GuoYX7dETEaJ1PaA2L/U2P/U2P/U3fwdBjN16WkaQCGe6SVKCDNdzXD7uBLuxveuxv\neuxv+g6GHid1UF5zlyRN7mA9c5ckTWJWh3tErIiIbRExFhHrOmx/eUTcVG3fEhFLBtjbooi4LSIe\niogHIuKvOtScHhHPRsTd1dcVnR5rBnt8NCLuq577gH88P5o+Ve2/eyPipAH2dnzLfrk7In4SEe9p\nqxn4/ouIayNiV0Tc3zJ2VETcGhEPV9+PnGDuBVXNwxFxQaeaGejtqoj4fvXz+0pEHDHB3EmPhRns\n7wMR8VjLz/CcCeZO+lqfwf5uaunt0Yi4e4K5M77/+i4zZ+UXzT8M8gjwemAecA+wrK3m3cA/V8ur\ngZsG2N8xwEnV8mHADzr0dzrwtSHuw0eB+ZNsPwf4Bs2/gXsKsGWIP+v/pnn/7lD3H/Am4CTg/pax\njwHrquV1wEc7zDsK2F59P7JaPnIAvb0FmFstf7RTb3WOhRns7wPAX9f4+U/6Wp+p/tq2/x1wxbD2\nX7+/ZvOZ+3JgLDO3Z+Ye4EZgVVvNKuBz1fKXgDMiotMf6+67zHw8M79XLf8UeAhYMIjn7qNVwHXZ\ntBk4IiKOGUIfZwCPZOZUP9TWN5n5XQ78+7+tx9nngHM7TD0LuDUzn8rMp4FbgRUz3VtmfjMz91ar\nm2n+jeOhmGDf1VHntT5tk/VX5cY7gBv6/bzDMpvDfQGwo2V9nAPDc39NdYA/C7x6IN21qC4HnQhs\n6bD51Ii4JyK+ERG/PtDGIIFvRsTWiFjbYXudfTwIq5n4RTXM/bfPazLzcWj+Tx04ukPNbNiX76L5\nm1gn3Y6FmXRJddno2gkuac2Gffd7wBOZ+fAE24e5/6ZkNod7pzPw9lt76tTMqIh4FfDvwHsy8ydt\nm79H81LDbwL/ANwyyN6A0zLzJOBs4M8j4k1t22fD/psHrAS+2GHzsPdfL4a6LyPiMmAvcP0EJd2O\nhZnyaeA44LeAx2le+mg39OMQWMPkZ+3D2n9TNpvDfRxY1LK+ENg5UU1EzAUOZ2q/Fk5JRBxCM9iv\nz8wvt2/PzJ9k5v9UyxuBQyJi/qD6y8yd1fddwFdo/vrbqs4+nmlnA9/LzCfaNwx7/7V4Yt/lqur7\nrg41Q9uX1Zu3fwicl9UF4nY1joUZkZlPZOYLmfl/wDUTPO9Qj8MqO94G3DRRzbD233TM5nC/E1ga\nEcdWZ3ergQ1tNRuAfXclvB349kQHd79V1+j+FXgoMz8+Qc2v7HsPICKW09zfTw6ov1dGxGH7lmm+\n8XZ/W9kG4J3VXTOnAM/uu/wwQBOeMQ1z/7VpPc4uAL7aoWYT8JaIOLK69PCWamxGRcQK4G+AlZn5\n8wlq6hwLM9Vf63s4fzTB89Z5rc+kNwPfz8zxThuHuf+mZdjv6E72RfNujh/QfCf9smrsSpoHMsAr\naP46Pwb8J/D6Afb2uzR/dbwXuLv6Oge4GLi4qrkEeIDmu/+bgd8ZYH+vr573nqqHffuvtb8Arq72\n731AY8A/31+iGdaHt4wNdf/R/B/N48DzNM8oL6T5Ps63gIer70dVtQ3gMy1z31Udi2PAnw2otzGa\n16v3HYP77h57LbBxsmNhQP19vjq27qUZ2Me091etH/BaH0R/1fhn9x1zLbUD33/9/vITqpJUoNl8\nWUaSNEWGuyQVyHCXpAIZ7pJUIMNdkgpkuEtSgQx3SSqQ4S5JBfp/OPagFm4vn4YAAAAASUVORK5C\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f987cdabef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(c_obama_us, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Корреляции между перменными снова нет. Количество упоминаний США и Барака Обамы в день никак не связаны."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Каких статей больше: статей о России и Путине или об Исламском государстве (запрещенной законом РФ террористическая организации)?**\n",
    "\n",
    "Снова нам надо найти строки, в которых встречаются слова:\n",
    "- Russia\n",
    "- Russian\n",
    "- Putin\n",
    "\n",
    "- ISIS\n",
    "- Islamic State\n",
    "\n",
    "Теперь нам надо проанализировать не целую строку за весь день, а каждый отдельный текст в ней, поэтому итерироваться будем по строкам таблицы, создадим array, а затем еще по каждому тексту в строке в отдельном блоке кода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_values(data_frame):\n",
    "    headings_list = []\n",
    "    for index in range(len(data_frame)):\n",
    "        single_row = data_frame.loc[index:index, :]\n",
    "        single_row_list = single_row.get_values()\n",
    "        headings_list.extend(single_row_list)\n",
    "    headings_array = np.array(headings_list)\n",
    "    return headings_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1212,
   "metadata": {},
   "outputs": [],
   "source": [
    "headings_array = get_values(df_tops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1062,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_cases(text_str, cases):\n",
    "    regexp = '|'.join(cases)\n",
    "    return len(tuple(re.finditer(regexp, text_str)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция `count_russia_isis` принимает список, строки в котором сравнивает с тьюплами `cases`. Если значение больше 0, это означает, что в тексте встретились слова из кейса и в зависимости от этого они отправляются в списки, от которых потом берется их длина, что и является количеством текстов. В конце просто сравниваем, каких получилось больше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_russia_isis(text_list):\n",
    "    cases_russia = ('Russia', 'Russian', 'Putin')\n",
    "    cases_isis = ('ISIS', 'Islamic State')\n",
    "    \n",
    "    count_cases_russia = len([None for text in text_list\n",
    "                              if count_cases(text, cases_russia) > 0])\n",
    "\n",
    "    count_cases_isis = len([None for text in text_list\n",
    "                            if count_cases(text, cases_isis) > 0])\n",
    "    if count_cases_russia > count_cases_isis:\n",
    "        print('There are more articles about Putin and Russia.\\nTexts about Russia:',\n",
    "             count_cases_russia, '\\nTexts about ISIS:', count_cases_isis)\n",
    "    else:\n",
    "        print('There are more articles about ISIS. \\nTexts about ISIS:',\n",
    "             count_cases_isis, '\\nTexts about Russia:', count_cases_russia)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heading type nan: nan\n",
      "Heading type nan: nan\n",
      "Heading type nan: nan\n",
      "Heading type nan: nan\n",
      "Heading type nan: nan\n",
      "Heading type nan: nan\n",
      "Heading type nan: nan\n"
     ]
    }
   ],
   "source": [
    "small_texts_list = []\n",
    "for row in headings_array:\n",
    "    for heading in row:\n",
    "        if heading is np.nan:\n",
    "            print('Heading type nan:', heading)                \n",
    "            continue\n",
    "        small_texts_list.append(heading)\n",
    "small_texts_arr = np.array(small_texts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49718"
      ]
     },
     "execution_count": 1217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(small_texts_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are more articles about Putin and Russia.\n",
      "Texts about Russia: 2964 \n",
      "Texts about ISIS: 845\n"
     ]
    }
   ],
   "source": [
    "count_russia_isis(small_texts_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**О каких кризисах (crisis) пишут статьи?**\n",
    "\n",
    "Для того, чтобы понять, о каких кризисах идет речь, кроме слова crisis из строки нам нужно выбрать его контекст. Это можно сделать с помощью n-грам. Попробуем использовать 5-граммы, где центральное слово crisis, а два слова справа и слева -- контекст. \n",
    "\n",
    "Здесь мы также будем рассматривать каждый заголовок отдельно*, чтобы избежать ситуации, когда слово crisis встречается в тексте более одного раза (возможно, такие случаи тоже встретятся, но будут довольно редки, и это не помешает нам достать основной контекст). \n",
    "\n",
    "*Здесь итерация по кажому тексту вшита в саму функцию `get_context_from_array`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context(word_list):\n",
    "#     print('get_context', word_list)\n",
    "    word_index = word_list.index('crisis')\n",
    "    left_index = word_index-2\n",
    "    if left_index < 0:\n",
    "        left_index = 0\n",
    "    context = word_list[left_index:(word_index+3)]\n",
    "    context = ' '.join(context)\n",
    "    return context\n",
    "    \n",
    "    \n",
    "    \n",
    "assert get_context(['a', 'crisis', 'b', 'c', 'd']) \\\n",
    "    == 'a crisis b c', \\\n",
    "    get_context(['a', 'crisis', 'b', 'c', 'd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context_from_array(headings_array):\n",
    "    for row in headings_array:\n",
    "        for heading in row:\n",
    "            if heading is np.nan:\n",
    "                print('Heading type nan:', heading)                \n",
    "                continue\n",
    "            heading = preprocess(heading)\n",
    "            heading = heading.split()\n",
    "#             print(heading)\n",
    "            if 'crisis' in heading:\n",
    "#                 heading = heading.split(preprocess(heading))\n",
    "                context = get_context(heading)\n",
    "                print('Context:', context)\n",
    "            else:\n",
    "                continue\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, посмотрим, о каких кризисах идет речь в новостях, выделим наиболее интересные и значимые:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: caucasus in crisis georgia invades\n",
      "Context: forecast georgian crisis 2 days\n",
      "Context: aids treatment crisis goes critical\n",
      "Context: the market crisis to be\n",
      "Context: wall street crisis ahmadinejad\n",
      "Context: a financial crisis the swedish\n",
      "Context: the economic crisis that s\n",
      "Context: and a crisis of the\n",
      "Context: german bank crisis the transformation\n",
      "Context: s financial crisis should be\n",
      "Context: from the crisis\n",
      "Context: world economic crisis deepens nikkei\n",
      "Context: the climate crisis\n",
      "Context: warns of crisis in afghanistan\n",
      "Context: dwarfs bank crisis\n",
      "Context: pakistan in crisis on mission\n",
      "Context: current financial crisis\n",
      "Context: the financial crisis stocks surge\n",
      "Context: global economic crisis likely to\n",
      "Context: world financial crisis deepens\n",
      "Context: worst food crisis in decade\n",
      "Context: iceland as crisis deepens\n",
      "Context: a lifetime crisis and possibly\n",
      "Context: s financial crisis is escalating\n",
      "Context: of food crisis\n",
      "Context: of currency crisis meltdown\n",
      "Context: money as crisis spreads\n",
      "Context: peak oil crisis within five\n",
      "Context: crisis creates a\n",
      "Context: global financial crisis should delay\n",
      "Context: crisis in paradise\n",
      "Context: of food crisis\n",
      "Context: the humanitarian crisis\n",
      "Context: zimbabwe health crisis a disaster\n",
      "Context: thai crisis exposes class\n",
      "Context: claims cholera crisis is over\n",
      "Context: on financial crisis had knowledge\n",
      "Context: the economic crisis right wing\n",
      "Context: the economic crisis\n",
      "Context: no humanitarian crisis in gaza\n",
      "Context: blown humanitarian crisis\n",
      "Context: the gaza crisis\n",
      "Context: s cholera crisis\n",
      "Context: crisis worsens for\n",
      "Context: global financial crisis\n",
      "Context: and humanitarian crisis in the\n",
      "Context: as cholera crisis in zimbabwe\n",
      "Context: icrc crisis unfolding in\n",
      "Context: by financial crisis tries to\n",
      "Context: for financial crisis\n",
      "Context: drinking water crisis in the\n",
      "Context: the financial crisis is driving\n",
      "Context: as global crisis worsens\n",
      "Context: puts current crisis into perspective\n",
      "Context: blame for crisis in darfur\n",
      "Context: paradise as crisis continues to\n",
      "Context: global economic crisis\n",
      "Context: off economic crisis\n",
      "Context: behind darfur crisis\n",
      "Context: the banking crisis insightful as\n",
      "Context: grapples with crisis of isolation\n",
      "Context: global economic crisis isn t\n",
      "Context: is this crisis good for\n",
      "Context: this global crisis watch switzerland\n",
      "Context: thailand s crisis\n",
      "Context: sri lanka crisis\n",
      "Context: sri lanka crisis deepens as\n",
      "Context: companies uses crisis as pretext\n",
      "Context: rape crisis in east\n",
      "Context: the financial crisis in iceland\n",
      "Context: s marriage crisis bring down\n",
      "Context: the financial crisis that i\n",
      "Context: woman this crisis is far\n",
      "Context: crisis in honduras\n",
      "Context: cause the crisis workers get\n",
      "Context: a further crisis for pakistan\n",
      "Context: of economic crisis ssangyong workers\n",
      "Context: unprecedented food crisis and huge\n",
      "Context: keeping political crisis alive\n",
      "Context: and energy crisis by 2030\n",
      "Heading type nan: nan\n",
      "Heading type nan: nan\n",
      "Heading type nan: nan\n",
      "Context: africa housing crisis movie shows\n",
      "Context: worst food crisis in 18\n",
      "Context: into total crisis i can\n",
      "Context: to food crisis\n",
      "Context: global financial crisis hamas is\n",
      "Context: collapse icelands crisis deepens\n",
      "Context: faces funding crisis\n",
      "Context: the honduran crisis ended last\n",
      "Context: ecuador energy crisis cripples production\n",
      "Context: its debt crisis\n",
      "Context: a food crisis remain very\n",
      "Heading type nan: nan\n",
      "Heading type nan: nan\n",
      "Context: of extreme crisis are desperate\n",
      "Context: the google crisis with state\n",
      "Context: the orphan crisis facing haiti\n",
      "Context: is in crisis assailed by\n",
      "Context: snowpocalypse worsening crisis in mongolia\n",
      "Context: worse deficit crisis than greece\n",
      "Context: avert a crisis\n",
      "Context: for currency crisis executed by\n",
      "Context: europe s crisis germans are\n",
      "Context: of rubbish crisis with giant\n",
      "Context: for the crisis one sign\n",
      "Context: crisis in kyrgyzstan\n",
      "Context: the kyrgyzstan crisis here is\n",
      "Context: worst credibility crisis since reformation\n",
      "Context: impending phosphorus crisis\n",
      "Context: the greek crisis is not\n",
      "Context: non judiciary crisis in turkey\n",
      "Context: 2008 financial crisis to the\n",
      "Context: europe debt crisis widens\n",
      "Context: popes brewing crisis in south\n",
      "Context: the financial crisis to pay\n",
      "Context: the difficult crisis that has\n",
      "Context: the greek crisis have in\n",
      "Context: athens financial crisis protests\n",
      "Context: see debt crisis as evidence\n",
      "Context: portugal unveils crisis tax to\n",
      "Context: redshirts as crisis escalates one\n",
      "Context: greek economic crisis turkish pm\n",
      "Context: the financial crisis and europe\n",
      "Context: the thai crisis\n",
      "Context: send euro crisis global\n",
      "Context: no humanitarian crisis in the\n",
      "Context: on korea crisis\n",
      "Context: no humanitarian crisis in the\n",
      "Context: global financial crisis europe is\n",
      "Context: current food crisis in north\n",
      "Context: the financial crisis or climate\n",
      "Context: healthcare crisis in north\n",
      "Context: another food crisis\n",
      "Context: no humanitarian crisis in gaza\n",
      "Context: lebanon crisis feared as\n",
      "Context: drastic oil crisis\n",
      "Context: global energy crisis dramatically shifting\n",
      "Context: manilas water crisis exposes impact\n",
      "Context: overall economic crisis\n",
      "Context: commonwealth games crisis\n",
      "Context: the financial crisis\n",
      "Context: the financial crisis\n",
      "Context: banks mortgage crisis just beginning\n",
      "Context: troops the crisis follows decades\n",
      "Context: massive banking crisis alone\n",
      "Context: as bank crisis deepens\n",
      "Context: on korean crisis says us\n",
      "Context: a fundamental crisis of legitimacy\n",
      "Context: prevent financial crisis\n",
      "Context: a humanitarian crisis\n",
      "Context: real drugs crisis the top\n",
      "Context: great food crisis of 2011\n",
      "Context: the banking crisis confirms raids\n",
      "Context: the arab crisis food energy\n",
      "Context: kunar a crisis is brewing\n",
      "Context: this financial crisis is being\n",
      "Context: over the crisis at their\n",
      "Context: japanese nuclear crisis than the\n",
      "Context: japan crisis is much\n",
      "Context: japan crisis they are\n",
      "Context: japans nuclear crisis government regulators\n",
      "Context: forgotten humanitarian crisis\n",
      "Context: s nuclear crisis is far\n",
      "Context: the financial crisis\n",
      "Context: middle east crisis has just\n",
      "Context: during econ crisis\n",
      "Context: ivory coast crisis 1000 killed\n",
      "Context: d ivoire crisis how the\n",
      "Context: raise fukushima crisis level from\n",
      "Context: of nuke crisis to the\n",
      "Context: japan s crisis one month\n",
      "Context: japan s crisis one month\n",
      "Heading type nan: nan\n",
      "Heading type nan: nan\n",
      "Context: burma crisis in shan\n",
      "Context: the nuclear crisis is over\n",
      "Context: a serious crisis\n",
      "Context: egypt in crisis talks as\n",
      "Context: the nuclear crisis are now\n",
      "Context: the nuclear crisis at the\n",
      "Context: as cucumber crisis grows\n",
      "Context: the nuclear crisis\n",
      "Context: japan nuclear crisis stricken fukushima\n",
      "Context: global financial crisis\n",
      "Context: our economic crisis are driving\n",
      "Context: into a crisis because of\n",
      "Context: from the crisis and explains\n",
      "Context: eurozone debt crisis but chinese\n",
      "Context: somalia food crisis reaching unimaginable\n",
      "Context: the euro crisis there is\n",
      "Context: the economic crisis has cost\n",
      "Context: japan nuclear crisis record high\n",
      "Context: yen as crisis grips world\n",
      "Context: a wider crisis of globalization\n",
      "Context: amid debt crisis german chancellor\n",
      "Context: its nuclear crisis was caused\n",
      "Context: the uk crisis study warns\n",
      "Context: the euro crisis and his\n",
      "Context: reporting the crisis\n",
      "Context: eurozone debt crisis is this\n",
      "Context: global economic crisis\n",
      "Context: a world crisis beware people\n",
      "Context: solved carbon crisis\n",
      "Context: s euro crisis lecture is\n",
      "Context: exploit the crisis to push\n",
      "Context: korean hunger crisis occasionally the\n",
      "Context: of looming crisis the australian\n",
      "Context: than economic crisis\n",
      "Context: a demographic crisis and worries\n",
      "Context: facing mounting crisis as activist\n",
      "Context: of a crisis\n",
      "Context: greek debt crisis as part\n",
      "Context: eurozone crisis banks agree\n",
      "Context: great gender crisis chinese families\n",
      "Context: greek crisis papandreou to\n",
      "Context: from iceland crisis is let\n",
      "Context: news italian crisis silvio berlusconi\n",
      "Context: banks as crisis deepens greeks\n",
      "Context: the euro crisis to boost\n",
      "Context: continuing euro crisis there is\n",
      "Context: next financial crisis will be\n",
      "Context: monti unveiling crisis plan in\n",
      "Context: sovereign debt crisis could be\n",
      "Context: the nuclear crisis began at\n",
      "Context: crisis in europe\n",
      "Context: a credit crisis in china\n",
      "Context: israeli rape crisis centers get\n",
      "Context: the debt crisis\n",
      "Context: despite debt crisis in 2011\n",
      "Context: an identity crisis after centuries\n",
      "Context: sovereign debt crisis gripping the\n",
      "Context: climate change crisis\n",
      "Context: crisis looms for\n",
      "Context: syria crisis almost 200\n",
      "Context: the eurozone crisis to wage\n",
      "Context: fix the crisis\n",
      "Context: the euro crisis\n",
      "Context: new financial crisis deeper and\n",
      "Context: from the crisis\n",
      "Context: currency crisis in iran\n",
      "Context: during the crisis\n",
      "Context: future health crisis\n",
      "Context: the debt crisis wants to\n",
      "Context: the euro crisis as investors\n",
      "Context: of economic crisis\n",
      "Context: crisis in syria\n",
      "Context: the financial crisis hurt the\n",
      "Context: generation the crisis hit nations\n",
      "Context: new european crisis spains 709\n",
      "Context: the economic crisis is taking\n",
      "Context: in huge crisis after credit\n",
      "Context: the eurozone crisis to an\n",
      "Context: child of crisis iceland recovers\n",
      "Context: the financial crisis says a\n",
      "Context: s financial crisis and said\n",
      "Context: crisis hit portugal\n",
      "Context: s reached crisis levels costing\n",
      "Context: s financial crisis lurched into\n",
      "Context: in tuition crisis\n",
      "Context: a food crisis of catastrophic\n",
      "Context: female infanticide crisis can the\n",
      "Context: the climate crisis history will\n",
      "Context: as global crisis deepens\n",
      "Context: amid economic crisis spain ponders\n",
      "Context: wetland to crisis point if\n",
      "Context: the banking crisis of 1931\n",
      "Context: the debt crisis worsens in\n",
      "Context: worsening debt crisis\n",
      "Context: public health crisis\n",
      "Context: the financial crisis says former\n",
      "Context: to the crisis in syria\n",
      "Context: libor banking crisis challenging american\n",
      "Context: international survey crisis batters global\n",
      "Context: food price crisis feared as\n",
      "Context: above eurozone crisis what has\n",
      "Context: a food crisis than most\n",
      "Context: effect eurozone crisis has led\n",
      "Context: in syria crisis and blames\n",
      "Context: severe water crisis report warns\n",
      "Context: of food crisis glencore trading\n",
      "Context: euro debt crisis intensifies\n",
      "Context: warns on crisis bloomberg\n",
      "Context: european debt crisis\n",
      "Context: syria crisis russia tells\n",
      "Context: says syria crisis is threat\n",
      "Context: close to crisis levels un\n",
      "Context: 2008 banking crisis their bank\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: growing global crisis depression could\n",
      "Context: the financial crisis\n",
      "Context: caribbean debt crisis has islands\n",
      "Context: hit by crisis greek society\n",
      "Context: gaza crisis tel aviv\n",
      "Context: global financial crisis grew to\n",
      "Context: gaza crisis palestinian shot\n",
      "Context: a political crisis\n",
      "Context: a financial crisis should be\n",
      "Context: sperm count crisis biggest ever\n",
      "Context: syria crisis food aid\n",
      "Context: despite euro crisis spiegel online\n",
      "Context: its economic crisis\n",
      "Context: mali crisis militants killed\n",
      "Context: air pollution crisis\n",
      "Context: s economic crisis are finding\n",
      "Context: if syria crisis worsens\n",
      "Context: the hostage crisis in algeria\n",
      "Context: water pollution crisis according to\n",
      "Context: critical housing crisis hong kongs\n",
      "Context: prolonged political crisis\n",
      "Context: north korea crisis gone too\n",
      "Context: north korea crisis foreign ministry\n",
      "Context: north korea crisis could escalate\n",
      "Context: financial crisis caused by\n",
      "Context: europe s crisis countries hide\n",
      "Context: the financial crisis as in\n",
      "Context: refugees says crisis may be\n",
      "Context: amid ongoing crisis\n",
      "Context: in the crisis in britain\n",
      "Context: greek debt crisis and bailout\n",
      "Context: the financial crisis could not\n",
      "Context: the financial crisis\n",
      "Context: live coverage crisis in egypt\n",
      "Context: brink of crisis a recent\n",
      "Context: over egypt crisis\n",
      "Context: as radiation crisis deepens\n",
      "Context: syria crisis child refugees\n",
      "Context: amid economic crisis\n",
      "Context: syria crisis russia and\n",
      "Context: syria crisis warplanes spotted\n",
      "Context: to the crisis on wednesday\n",
      "Context: 1994 rwandan crisis a documentary\n",
      "Context: syria crisis war of\n",
      "Context: the economic crisis some ex\n",
      "Context: solve debt crisis\n",
      "Context: the financial crisis\n",
      "Context: youth unemployment crisis in one\n",
      "Context: contain diplomatic crisis as madrid\n",
      "Context: avert climate crisis\n",
      "Context: exacerbated humanitarian crisis\n",
      "Context: ukraine s crisis is getting\n",
      "Context: the silent crisis vietnams elephants\n",
      "Context: in political crisis\n",
      "Context: unusual currency crisis a pilgrim\n",
      "Context: the political crisis in ukraine\n",
      "Context: a jobs crisis and economic\n",
      "Context: ukraines political crisis\n",
      "Context: the ukraine crisis with the\n",
      "Context: ukraine crisis russia stands\n",
      "Context: over the crisis in ukraine\n",
      "Context: ukraine crisis ukrainians rush\n",
      "Context: declaring ukraine crisis an extraordinary\n",
      "Context: for ukraine crisis\n",
      "Context: amid crimea crisis russia proposes\n",
      "Context: ukraine crisis us sends\n",
      "Context: ukraine crisis us will\n",
      "Context: the ukraine crisis than it\n",
      "Context: the political crisis in ukraine\n",
      "Context: to smog crisis\n",
      "Context: iranian nuclear crisis diplomatically and\n",
      "Context: global financial crisis\n",
      "Context: if ukraine crisis escalates\n",
      "Context: ukraine crisis no sign\n",
      "Context: ukraine crisis poland asks\n",
      "Context: news ukraine crisis violent brawl\n",
      "Context: deepening immigration crisis\n",
      "Context: the ukraine crisis against russia\n",
      "Context: of the crisis in ukraine\n",
      "Context: the ukraine crisis russia s\n",
      "Context: of financial crisis as showdown\n",
      "Context: jeapordised by crisis in ukraine\n",
      "Context: ukraine crisis nato to\n",
      "Context: as ukraine crisis scars economy\n",
      "Context: becomes hostage crisis as separatists\n",
      "Context: ukraine crisis army moves\n",
      "Context: ukraine crisis eu set\n",
      "Context: as ukraine crisis continues us\n",
      "Context: after crimea crisis nato will\n",
      "Context: ukraine crisis national guardsmen\n",
      "Context: have reached crisis proportions in\n",
      "Context: thirst water crisis lies on\n",
      "Context: its political crisis at the\n",
      "Context: the syrian crisis to the\n",
      "Context: ukraine crisis many soldiers\n",
      "Context: since financial crisis still resisting\n",
      "Context: covering the crisis in ukraine\n",
      "Context: rebels in crisis after donetsk\n",
      "Context: the ukraine crisis\n",
      "Context: crisis in iraq\n",
      "Context: the economic crisis in europe\n",
      "Context: over iraq crisis\n",
      "Context: iraq crisis isis seizes\n",
      "Context: iraq crisis britain and\n",
      "Context: addressing ongoing crisis\n",
      "Context: global financial crisis to happen\n",
      "Context: independent iraq crisis tony blair\n",
      "Context: ebola crisis in west\n",
      "Context: gaza crisis far right\n",
      "Context: gaza crisis isis pledge\n",
      "Context: the ebola crisis in west\n",
      "Context: iraq crisis us to\n",
      "Context: at netanyahu crisis in us\n",
      "Context: ukraine crisis t 72\n",
      "Context: on ukraine crisis\n",
      "Context: on ukraine crisis\n",
      "Context: the ukrainian crisis and using\n",
      "Context: ebola crisis obama administration\n",
      "Context: the ukraine crisis bite\n",
      "Context: ongoing ebola crisis in west\n",
      "Context: for ukraine crisis us trying\n",
      "Context: the financial crisis\n",
      "Context: ukraine crisis petro poroshenko\n",
      "Context: over ukraine crisis\n",
      "Context: since 2008 crisis\n",
      "Context: face food crisis as un\n",
      "Context: maldives in crisis as water\n",
      "Context: the word crisis in public\n",
      "Context: crisis struck russian\n",
      "Context: slides into crisis\n",
      "Context: ongoing financial crisis\n",
      "Context: as humanitarian crisis unfolds\n",
      "Context: growing economic crisis\n",
      "Context: its financial crisis\n",
      "Context: caused ukraine crisis putin\n",
      "Context: engineered oil crisis dallas fed\n",
      "Context: ongoing refugee crisis in the\n",
      "Context: amid russia crisis germany plans\n",
      "Context: over the crisis in ukraine\n",
      "Context: s economic crisis we re\n",
      "Context: ukraine crisis four dead\n",
      "Context: as economic crisis deepens\n",
      "Context: worth since crisis\n",
      "Context: macedonian crisis ends with\n",
      "Context: an ammunition crisis in the\n",
      "Context: dangerous financial crisis\n",
      "Context: fifa crisis south africa\n",
      "Context: fifa crisis jack warner\n",
      "Context: after greek crisis talks fell\n",
      "Context: the financial crisis\n",
      "Context: outside economic crisis the iea\n",
      "Context: off potential crisis in the\n",
      "Context: greek crisis more than\n",
      "Context: greek crisis surrender fiscal\n",
      "Context: five week crisis shut down\n",
      "Context: country s crisis to the\n",
      "Context: migrants crisis slovakia will\n",
      "Context: migrants crisis germany s\n",
      "Context: migration crisis germany france\n",
      "Context: help european crisis\n",
      "Context: european refugee crisis with the\n",
      "Context: yemen crisis two red\n",
      "Context: pm migrant crisis is a\n",
      "Context: amid refugee crisis hungary prime\n",
      "Context: of refugee crisis are wars\n",
      "Context: europe migrant crisis hungary will\n",
      "Context: for refugee crisis in europe\n",
      "Context: asylum seeker crisis according to\n",
      "Context: on refugee crisis unfortunately only\n",
      "Context: dwarf current crisis tesla s\n",
      "Context: global financial crisis\n",
      "Context: a migration crisis\n",
      "Context: the financial crisis has moved\n",
      "Context: refugee crisis nine month\n",
      "Context: in financial crisis\n",
      "Context: the migrant crisis\n",
      "Context: worst climate crisis in the\n",
      "Context: of humanitarian crisis\n",
      "Context: a good crisis by those\n",
      "Context: migrant crisis turkey to\n",
      "Context: amid migrant crisis criticism\n",
      "Context: yemen crisis sanaa resident\n",
      "Context: as cash crisis deepens\n",
      "Context: refugee crisis could lead\n",
      "Context: global superbug crisis in wake\n",
      "Context: in refugee crisis\n",
      "Context: global health crisis and governments\n",
      "Context: news migrant crisis sweden border\n",
      "Context: regional diplomatic crisis following the\n",
      "Context: in refugee crisis\n",
      "Context: migrant crisis coach full\n",
      "Context: their budget crisis made worse\n",
      "Context: migration crisis can destroy\n",
      "Context: the migrant crisis could destroy\n",
      "Context: the refugee crisis continues\n",
      "Context: epidemic reaches crisis levels\n",
      "Context: exploit refugee crisis\n",
      "Context: over refugee crisis and fears\n",
      "Context: news migrant crisis dutch plan\n",
      "Context: fukushima nuclear crisis far from\n",
      "Context: and the crisis is far\n",
      "Context: to tackle crisis\n",
      "Context: potential food crisis amid a\n",
      "Context: weaponising refugee crisis to destabilise\n",
      "Context: time of crisis for oil\n",
      "Context: refugee crisis puts truckers\n",
      "Context: a legal crisis that has\n",
      "Context: group into crisis mode as\n",
      "Context: migrant crisis macedonia shuts\n",
      "Context: refugee crisis balkan route\n",
      "Context: mounting political crisis supreme court\n",
      "Context: as economic crisis bites nearly\n",
      "Context: fresh financial crisis\n",
      "Context: barrier reef crisis in queensland\n",
      "Context: off power crisis\n",
      "Context: the financial crisis bloomberg\n",
      "Context: reached a crisis point after\n",
      "Context: worst food crisis since 1985\n",
      "Context: coral bleaching crisis an official\n",
      "Context: migrant crisis is fueling\n",
      "Context: ongoing political crisis now brazilian\n",
      "Context: s dementia crisis hits record\n",
      "Context: have a crisis\n"
     ]
    }
   ],
   "source": [
    "get_context_from_array(headings_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Кризисы:**\n",
    "1. Кавказский кризис (война Грузии и Южной Осетии)\n",
    "2. \"Медицинские\" кризисы (кризис лечения СПИДа, кризис холеры\n",
    "3. Мировой финансовый/экономический кризис\n",
    "4. Климатический кризис\n",
    "5. Нефтяной кризис\n",
    "6. Региональные кризисы (Тайланд, Шри-Ланка, Греция, Киргизия, Крым)\n",
    "7. Кризис насилия на Ближнем Востоке\n",
    "8. Пищевой кризис\n",
    "9. Демографический кризис\n",
    "10. Политические кризисы (политика, беженцы).\n",
    "11. Энергетический кризис итд."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть II. Классификация ##\n",
    "\n",
    "Перейдем к решению нашей основной задачи -- классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка обучающей и тестовой выборки ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из обучающего датафрейма извлечем только те записи, где DJIA равен 0 и прогоним через функцию предобработки `preprocess_to_list`. Поскольку функция отдает нам список из текстов, каждому из них надо снова назначить оригинальную метку класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = df_news_initial[df_news_initial['Date'] < '2015-01-01']\n",
    "test = df_news_initial[df_news_initial['Date'] > '2014-12-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_neg = train.loc[train['Label'] == 0]\n",
    "train_neg_tops = train_neg.loc[:, 'Top1':'Top25']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_to_list(data_frame):\n",
    "    texts_list = []\n",
    "    for index in range(len(data_frame)):\n",
    "        single_row = data_frame.loc[index:index, :]\n",
    "        headings_array = single_row.get_values()\n",
    "        for row in headings_array:\n",
    "            row_texts_list = []\n",
    "            for heading in row:\n",
    "                if heading is np.nan:\n",
    "                    print('Heading type nan:', heading)\n",
    "                    row_texts_list.append('')                \n",
    "                    continue\n",
    "                str_heading_text = preprocess(heading)\n",
    "                row_texts_list.append(str_heading_text)\n",
    "            row_texts_list = ' '.join(row_texts_list)\n",
    "            texts_list.append(row_texts_list)\n",
    "    return texts_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1233,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_neg_texts = preprocess_to_list(train_neg_tops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Назначим каждому тексту метку 0 и создадим тьюпл из текстов и меток к ним."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1235,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_neg_tup = [('0', text) for text in train_neg_texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем то же самое для строк с DJIA 1 и объединим результаты в датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_pos = train.loc[train['Label'] == 1]\n",
    "train_pos_tops = train_pos.loc[:, 'Top1':'Top25']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heading type nan: nan\n",
      "Heading type nan: nan\n",
      "Heading type nan: nan\n",
      "Heading type nan: nan\n",
      "Heading type nan: nan\n",
      "Heading type nan: nan\n",
      "Heading type nan: nan\n"
     ]
    }
   ],
   "source": [
    "train_pos_texts = preprocess_to_list(train_pos_tops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_pos_tup = [('1', text) for text in train_pos_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_tups = train_neg_tup + train_pos_tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>after finding two groups of males the force ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>people are being slaughtered like sheep gunmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>the inhumane detention conditions of bradley m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>defamation of religion is now a human rights v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>us troops and contractors caused substantial d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class                                               text\n",
       "0     1  after finding two groups of males the force ex...\n",
       "1     1  people are being slaughtered like sheep gunmen...\n",
       "2     0  the inhumane detention conditions of bradley m...\n",
       "3     1  defamation of religion is now a human rights v...\n",
       "4     1  us troops and contractors caused substantial d..."
      ]
     },
     "execution_count": 1240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.DataFrame(train_tups, columns=['class', 'text'])\n",
    "df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получаем обучающую выборку. Аналогичным образом обрабатываем тестовые данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_neg = test.loc[test['Label'] == 0]\n",
    "test_neg_tops = test_neg.loc[:, 'Top1':'Top25']\n",
    "test_neg_tops = test_neg_tops.reset_index(drop=True)\n",
    "test_neg_texts = preprocess_to_list(test_neg_tops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_neg_tup = [('0', text) for text in test_neg_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pos = test.loc[test['Label'] == 1]\n",
    "test_pos_tops = test_pos.loc[:, 'Top1':'Top25']\n",
    "test_pos_tops = test_pos_tops.reset_index(drop=True)\n",
    "test_pos_texts = preprocess_to_list(test_pos_tops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pos_tup = [('1', text) for text in test_pos_texts]\n",
    "test_tups = test_neg_tup + test_pos_tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>brazil blogger known for reporting on corrupti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>nigeria outlaws female genital mutilation peti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>beijing has issued its first ever red alert ov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>a 117 year old woman in mexico city finally re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>lenovo caught installing adware on new compute...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class                                               text\n",
       "0     1  brazil blogger known for reporting on corrupti...\n",
       "1     1  nigeria outlaws female genital mutilation peti...\n",
       "2     0  beijing has issued its first ever red alert ov...\n",
       "3     1  a 117 year old woman in mexico city finally re...\n",
       "4     0  lenovo caught installing adware on new compute..."
      ]
     },
     "execution_count": 1245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.DataFrame(test_tups, columns=['class', 'text'])\n",
    "df_test = df_test.sample(frac=1).reset_index(drop=True)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение классификаторов ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем использовать классификаторы MultinomialNB и LinearSVC из пакета **sklearn**. В качестве метрик качества берем F-меру и аккуратность. Будем менять разные параметры и смотреть, как изменяется качество классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Наивный Байес ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(ngram_range = [3,3], analyzer = 'word',  min_df = 2, stop_words='english')\n",
    "X_train = count_vect.fit_transform(df_train.text)\n",
    "y_train = df_train['class'].values\n",
    "\n",
    "X_test = count_vect.transform(df_test.text)\n",
    "y_test = df_test['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.001, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 878,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = MultinomialNB(alpha=0.001)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Без удаления стоп-слов ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.542328042328\n",
      "F1-measure (micro): 0.542328042328\n",
      "F1-measure (macro): 0.517953103001\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score:', accuracy_score(y_test, y_predict))\n",
    "print('F1-measure (micro):', f1_score(y_test, y_predict, average='micro'))\n",
    "print('F1-measure (macro):', f1_score(y_test, y_predict, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### С удалением стоп-слов, alpha=1 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.555555555556\n",
      "F1-measure (micro): 0.555555555556\n",
      "F1-measure (macro): 0.512781954887\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score:', accuracy_score(y_test, y_predict))\n",
    "print('F1-measure (micro):', f1_score(y_test, y_predict, average='micro'))\n",
    "print('F1-measure (macro):', f1_score(y_test, y_predict, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### alpha = 0.5 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.558201058201\n",
      "F1-measure (micro): 0.558201058201\n",
      "F1-measure (macro): 0.516509271386\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score:', accuracy_score(y_test, y_predict))\n",
    "print('F1-measure (micro):', f1_score(y_test, y_predict, average='micro'))\n",
    "print('F1-measure (macro):', f1_score(y_test, y_predict, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### alpha = 0.1 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.555555555556\n",
      "F1-measure (micro): 0.555555555556\n",
      "F1-measure (macro): 0.516049382716\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score:', accuracy_score(y_test, y_predict))\n",
    "print('F1-measure (micro):', f1_score(y_test, y_predict, average='micro'))\n",
    "print('F1-measure (macro):', f1_score(y_test, y_predict, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### alpha = 0.001 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.550264550265\n",
      "F1-measure (micro): 0.550264550265\n",
      "F1-measure (macro): 0.511880165289\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score:', accuracy_score(y_test, y_predict))\n",
    "print('F1-measure (micro):', f1_score(y_test, y_predict, average='micro'))\n",
    "print('F1-measure (macro):', f1_score(y_test, y_predict, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно изменение сглаживающего параметра в пределах единицы не сильно влияет на качество классификации. Главное, чтобы его значение не было равно нулю.\n",
    "\n",
    "Попробуем использовать **tf-idf** преобразование."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer()\n",
    "X_train = tfidf_vect.fit_transform(df_train.text)\n",
    "y_train = df_train['class'].values\n",
    "\n",
    "X_test = tfidf_vect.transform(df_test.text)\n",
    "y_test = df_test['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 835,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.550264550265\n",
      "F1-measure (micro): 0.550264550265\n",
      "F1-measure (macro): 0.511880165289\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score:', accuracy_score(y_test, y_predict))\n",
    "print('F1-measure (micro):', f1_score(y_test, y_predict, average='micro'))\n",
    "print('F1-measure (macro):', f1_score(y_test, y_predict, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пока наилучшего результата удалось достичь с использованием CountVectorizer с выделением словарных триграммов. TF-IDF преобразование никак не помогло."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVC ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range = [3,3], analyzer = 'word', min_df = 2)\n",
    "\n",
    "X_train = vect.fit_transform(df_train.text)\n",
    "y_train = df_train['class'].values\n",
    "\n",
    "X_test = vect.transform(df_test.text)\n",
    "y_test = df_test['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 849,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LinearSVC()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predict = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Результат с использованием стоп-слов ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.544973544974\n",
      "F1-measure (micro): 0.544973544974\n",
      "F1-measure (macro): 0.502874969415\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score:', accuracy_score(y_test, y_predict))\n",
    "print('F1-measure (micro):', f1_score(y_test, y_predict, average='micro'))\n",
    "print('F1-measure (macro):', f1_score(y_test, y_predict, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Результат без использования стоп-слов ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.550264550265\n",
      "F1-measure (micro): 0.550264550265\n",
      "F1-measure (macro): 0.505266075388\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score:', accuracy_score(y_test, y_predict))\n",
    "print('F1-measure (micro):', f1_score(y_test, y_predict, average='micro'))\n",
    "print('F1-measure (macro):', f1_score(y_test, y_predict, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интересно, что без удаления стоп-слов LinearSVC работает лучше, чем наивный Байес, но если удалять стоп-слова, то качество классификации немного ухудшается у LinearSVC, но повышается у наивного Байеса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сингулярное разложение ###\n",
    "Далее попробуем использовать сингулярное разложение и посмотрим, улучшится ли результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearSVC ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range = [3,3], analyzer = 'word', min_df = 2)\n",
    "\n",
    "X_train = vect.fit_transform(df_train.text)\n",
    "y_train = df_train['class'].values\n",
    "\n",
    "X_test = vect.transform(df_test.text)\n",
    "y_test = df_test['class'].values\n",
    "\n",
    "svd = TruncatedSVD(n_components=1000)\n",
    "X_train = svd.fit_transform(X_train, y_train)\n",
    "X_test = svd.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = LinearSVC()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_predict = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.550264550265\n",
      "F1-measure (micro): 0.550264550265\n",
      "F1-measure (macro): 0.505266075388\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score:', accuracy_score(y_test, y_predict))\n",
    "print('F1-measure (micro):', f1_score(y_test, y_predict, average='micro'))\n",
    "print('F1-measure (macro):', f1_score(y_test, y_predict, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для LinearSVC с сингулярным разложением ничего не изменилось. Применить SVD к наивному Байесу не представляется возможным, поскольку на вход он принимает только целые числа. Но можно попытаться сократить признаковое пространство другими способами, например, при помощи **VarienceTreshold**, убирая фичи с низкой varience или найти **KBest** признаков. Воспользуемся вторым способом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range = [3,3], analyzer = 'word', min_df = 2, stop_words='english')\n",
    "\n",
    "X_train = vect.fit_transform(df_train.text)\n",
    "y_train = df_train['class'].values\n",
    "\n",
    "X_test = vect.transform(df_test.text)\n",
    "y_test = df_test['class'].values\n",
    "\n",
    "best_features = SelectKBest(k=1000)\n",
    "X_train = best_features.fit_transform(X_train, y_train)\n",
    "X_test = best_features.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_predict = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.560846560847\n",
      "F1-measure (micro): 0.560846560847\n",
      "F1-measure (macro): 0.505952380952\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score:', accuracy_score(y_test, y_predict))\n",
    "print('F1-measure (micro):', f1_score(y_test, y_predict, average='micro'))\n",
    "print('F1-measure (macro):', f1_score(y_test, y_predict, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итог ## \n",
    "Максимальной аккуратности 56% нам удалось достичь при использовании классификатора наивного Байеса и выбора К лучших признаков и с удалением стоп-слов. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть III. NER или именованные сущности в качестве признаков ##\n",
    "\n",
    "State of the art в области NER считается Stanford NER tagger, реализованный на CRF модели. Стендфордская LSTM-CRF модель работает с символьно-векторным представлением слов, полученных при обучении на размеченных корпусах текстов.\n",
    "\n",
    "*CRF (Conditional Random Fields) -- метод моделирования, использующийся в машинном обучении для распознавания паттернов, принимающий во внимание контекст слова.\n",
    "\n",
    "*LSTM (Long Short Term Memory) -- особый вид рекуррентных нейронных сетей, способных к запоминанию длинных зависимостей. Это означает, что при использовании LSTM мы можем опираться на большее количество слов контекста для предсказания следующего. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JAVAHOME='/usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java'\n"
     ]
    }
   ],
   "source": [
    "%env JAVAHOME='/usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java'\n",
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.internals import find_jars_within_path\n",
    "from nltk import word_tokenize\n",
    "jar = '/home/nst/mount/data/linguistics_hse/machine_learning/stanford-ner-2014-06-16/stanford-ner-3.4.jar'\n",
    "model = '/home/nst/mount/data/linguistics_hse/machine_learning/stanford-ner-2014-06-16/classifiers/english.all.3class.distsim.crf.ser.gz'\n",
    "\n",
    "ner_tagger = StanfordNERTagger(model, jar, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('George', 'PERSON'), ('Washington', 'PERSON'), ('was', 'O'), ('the', 'O'), ('first', 'O'), ('US', 'LOCATION'), ('president', 'O')]\n",
      "CPU times: user 4 ms, sys: 144 ms, total: 148 ms\n",
      "Wall time: 4.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text = 'George Washington was the first US president'\n",
    "print(ner_tagger.tag(word_tokenize(text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучающая выборка ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для извлечения именованных сущностей с помощью `StanfordNERtagger` напишем функцию, которая будет возвращать список именованных сущностей для каждого текста. И преобразуем функцию препроцессинга для того, чтобы она выдавала нам большую строку из всех текстов, где они разделены запятыми."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ner_to_list (text_string):\n",
    "    named_entities_list = []\n",
    "    ne_tuples_list = ner_tagger.tag(word_tokenize(text_string))\n",
    "    for word, tag in ne_tuples_list:\n",
    "        if word == ',':\n",
    "            named_entities_list.append(word)\n",
    "            continue\n",
    "        if tag == 'O':\n",
    "            continue\n",
    "        named_entities_list.append(word)            \n",
    "    named_entities_str = ' '.join(named_entities_list)\n",
    "    ner_texts = named_entities_str.split(',')            \n",
    "    return ner_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_to_ner(data_frame):\n",
    "    texts_list = []\n",
    "    for index in range(len(data_frame)):\n",
    "        single_row = data_frame.loc[index:index, :]\n",
    "        headings_array = single_row.get_values()\n",
    "        for row in headings_array:\n",
    "            row_texts_list = []\n",
    "            for heading in row:\n",
    "                if heading is np.nan:\n",
    "                    print('Heading type nan:', heading)\n",
    "                    row_texts_list.append('')                \n",
    "                    continue\n",
    "                del_punctuation = re.findall(r'\\w+', heading)\n",
    "                str_heading_text = ' '.join(del_punctuation)\n",
    "                row_texts_list.append(str_heading_text)\n",
    "            row_texts_list = ' '.join(row_texts_list)\n",
    "            texts_list.append(row_texts_list)\n",
    "    texts_str = ','.join(texts_list)\n",
    "    return texts_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_neg_ner = train.loc[train['Label'] == 0]\n",
    "train_neg_tops_ner = train_neg_ner.loc[:, 'Top1':'Top25']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_neg_texts_ner = preprocess_to_ner(train_neg_tops_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.26 s, sys: 492 ms, total: 1.75 s\n",
      "Wall time: 48.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_neg_ner_list = ner_to_list(train_neg_texts_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_neg_tup_ner = [('0', text) for text in train_neg_ner_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heading type nan: nan\n",
      "Heading type nan: nan\n",
      "Heading type nan: nan\n",
      "Heading type nan: nan\n",
      "Heading type nan: nan\n",
      "Heading type nan: nan\n",
      "Heading type nan: nan\n"
     ]
    }
   ],
   "source": [
    "train_pos_ner = train.loc[train['Label'] == 1]\n",
    "train_pos_tops_ner = train_pos_ner.loc[:, 'Top1':'Top25']\n",
    "train_pos_texts_ner = preprocess_to_ner(train_pos_tops_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.72 s, sys: 360 ms, total: 2.08 s\n",
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_pos_ner_list = ner_to_list(train_pos_texts_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_pos_tup_ner = [('1', text) for text in train_pos_ner_list]\n",
    "train_tups_ner = train_neg_tup_ner + train_pos_tup_ner\n",
    "df_train_ner = pd.DataFrame(train_tups_ner, columns=['class', 'text'])\n",
    "df_train_ner = df_train_ner.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cambodian US Israel IDF Iran Israel Iran Paki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>America Nato Iraq Bush Georgian Israeli Russia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>ICC Sudan Omar al Bashir Darfur Gaza Google I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Prague TV Tower World Gigapixel MegaZoom Isra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class                                               text\n",
       "0     1   Cambodian US Israel IDF Iran Israel Iran Paki...\n",
       "1     1  America Nato Iraq Bush Georgian Israeli Russia...\n",
       "2     0   ICC Sudan Omar al Bashir Darfur Gaza Google I...\n",
       "3     1   Prague TV Tower World Gigapixel MegaZoom Isra..."
      ]
     },
     "execution_count": 1258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_ner.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тестовая выборка ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_neg_ner = test.loc[test['Label'] == 0]\n",
    "test_neg_tops_ner = test_neg_ner.loc[:, 'Top1':'Top25']\n",
    "test_neg_tops_ner = test_neg_tops_ner.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_neg_texts_ner = preprocess_to_ner(test_neg_tops_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_neg_ner_list = ner_to_list(test_neg_texts_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_neg_tup_ner = [('0', text) for text in test_neg_ner_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pos_ner = test.loc[test['Label'] == 1]\n",
    "test_pos_tops_ner = test_pos_ner.loc[:, 'Top1':'Top25']\n",
    "test_pos_tops_ner = test_pos_tops_ner.reset_index(drop=True)\n",
    "test_pos_texts_ner = preprocess_to_ner(test_pos_tops_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pos_ner_list = ner_to_list(test_pos_texts_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pos_tup_ner = [('1', text) for text in test_pos_ner_list]\n",
    "test_tups_ner = test_neg_tup_ner + test_pos_tup_ner\n",
    "df_test_ner = pd.DataFrame(test_tups_ner, columns=['class', 'text'])\n",
    "df_test_ner = df_test_ner.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>South Korea North Korea Paris Julian Assange ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Pope Francis Britain Putin Russia Russia Crim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Jordan Iraq Ukraine Jordan Abdullah II ISIS E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Beijing Europe World Germany Chile NATO Syria...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class                                               text\n",
       "0     0   South Korea North Korea Paris Julian Assange ...\n",
       "1     0   Pope Francis Britain Putin Russia Russia Crim...\n",
       "2     1   Jordan Iraq Ukraine Jordan Abdullah II ISIS E...\n",
       "3     0   Beijing Europe World Germany Chile NATO Syria..."
      ]
     },
     "execution_count": 754,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_ner.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение классификаторов на NE ###\n",
    "Попробуем использовать все те же классификаторы, что мы использовали и ранее: MultinomialNB и LinearSVC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearSVC ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer()\n",
    "\n",
    "X_train = vect.fit_transform(df_train_ner.text)\n",
    "y_train = df_train_ner['class'].values\n",
    "\n",
    "X_test = vect.transform(df_test_ner.text)\n",
    "y_test = df_test_ner['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = LinearSVC()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_predict = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.5\n",
      "F1-measure (micro): 0.5\n",
      "F1-measure (macro): 0.472766884532\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score:', accuracy_score(y_test, y_predict))\n",
    "print('F1-measure (micro):', f1_score(y_test, y_predict, average='micro'))\n",
    "print('F1-measure (macro):', f1_score(y_test, y_predict, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Наивный Байес ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train = count_vect.fit_transform(df_train_ner.text)\n",
    "y_train = df_train_ner['class'].values\n",
    "\n",
    "X_test = count_vect.transform(df_test_ner.text)\n",
    "y_test = df_test_ner['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = MultinomialNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_predict = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.508021390374\n",
      "F1-measure (micro): 0.508021390374\n",
      "F1-measure (macro): 0.407575757576\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score:', accuracy_score(y_test, y_predict))\n",
    "print('F1-measure (micro):', f1_score(y_test, y_predict, average='micro'))\n",
    "print('F1-measure (macro):', f1_score(y_test, y_predict, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Итог ###\n",
    "\n",
    "Именнованные сущности, к сожалению, никак не помогают улучшить качество классификации и даже ухудшают его."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы ##\n",
    "\n",
    "Оказалось, что классификация текстов на основе изменения индекса Доу Джонса не такая простая задача. \n",
    "\n",
    "Здесь видятся две проблемы: \n",
    "\n",
    "1. Кажется, что для построения классификации одного индекса не достаточно, несмотря на достаточный размер коллекции. Для улучшения качества классификации можно было бы ввести какие-то дополнительные данные помимо текстов. \n",
    "\n",
    "2. Возможно, качество было бы выше, если бы изменение индекса коррелировало бы с параметрами, полученными на основе текстов (средняя длина, упоминание личностей, что мы и попытались найти в первой части).\n",
    "\n",
    "Технические выводы:\n",
    "\n",
    "1. Оба классификатора дают примерно одинаковый максимальный результат при изменении способа векторного представления и других параметров классификации.\n",
    "2. Извлечение именованных сущностей никак не улучшает качество классификации. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
